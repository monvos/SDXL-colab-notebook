{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "McvSC3IXPV21"
      },
      "outputs": [],
      "source": [
        "!pip install diffusers --upgrade\n",
        "!pip install invisible_watermark transformers accelerate safetensors"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ####**Settings:**\n",
        "\n",
        "\n",
        "\n",
        "from diffusers import DiffusionPipeline\n",
        "from diffusers import (\n",
        "    DDIMScheduler,\n",
        "    DPMSolverMultistepScheduler,\n",
        ")\n",
        "import torch\n",
        "import time\n",
        "\n",
        "# seed = torch.Generator(\"cuda\").manual_seed(1517224853)\n",
        "\n",
        "# SDXL\n",
        "model_path = \"stabilityai/stable-diffusion-xl-base-1.0\" #@param{type: 'string'}\n",
        "refiner_path = \"stabilityai/stable-diffusion-xl-refiner-1.0\" #@param{type: 'string'}\n",
        "\n",
        "ddim = DDIMScheduler.from_pretrained(model_path, subfolder=\"scheduler\")\n",
        "DPM_2M_Karras = DPMSolverMultistepScheduler.from_pretrained(model_path, subfolder=\"scheduler\", use_karras_sigmas=True)\n",
        "DPM_2M_SDE_Karras = DPMSolverMultistepScheduler.from_pretrained(model_path, subfolder=\"scheduler\", use_karras_sigmas=True, algorithm_type=\"sde-dpmsolver++\")\n",
        "\n",
        "\n",
        "scheduler = DPM_2M_Karras #@param [\"ddim\", \"DPM_2M_Karras\", \"DPM_2M_SDE_Karras\"] {type:\"raw\"}\n",
        "\n",
        "# load both base & refiner\n",
        "base = DiffusionPipeline.from_pretrained(\n",
        "    model_path, scheduler=scheduler, torch_dtype=torch.float16, variant=\"fp16\", use_safetensors=True\n",
        ")\n",
        "base.to(\"cuda\")\n",
        "refiner = DiffusionPipeline.from_pretrained(\n",
        "    refiner_path,\n",
        "    scheduler=scheduler,\n",
        "    text_encoder_2=base.text_encoder_2,\n",
        "    vae=base.vae,\n",
        "    torch_dtype=torch.float16,\n",
        "    use_safetensors=True,\n",
        "    variant=\"fp16\",\n",
        ")\n",
        "refiner.to(\"cuda\")\n",
        "\n",
        "# Define how many steps and what % of steps to be run on each experts (80/20) here\n",
        "n_steps = 20 #@param{type: 'number'}\n",
        "width = 1024 #@param{type: 'number'}\n",
        "height = 1024 #@param{type: 'number'}\n",
        "high_noise_frac = 0.8\n",
        "\n",
        "prompt = \"\" #@param{type: 'string'}\n",
        "negative_prompt = \"\" #@param{type: 'string'}\n",
        "\n",
        "# run both experts\n",
        "image = base(\n",
        "    prompt=prompt,\n",
        "    width=width,\n",
        "    height=height,\n",
        "    negative_prompt=negative_prompt,\n",
        "    num_inference_steps=n_steps,\n",
        "    denoising_end=high_noise_frac,\n",
        "    output_type=\"latent\",\n",
        ").images\n",
        "image = refiner(\n",
        "    prompt=prompt,\n",
        "    negative_prompt=negative_prompt,\n",
        "    num_inference_steps=n_steps,\n",
        "    denoising_start=high_noise_frac,\n",
        "    image=image,\n",
        ").images[0]\n",
        "\n",
        "image.save(\"random_\"+ str(int(time.time())) +\".png\")\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "InR51AOtRGa2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}